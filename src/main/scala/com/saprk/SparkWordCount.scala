package com.saprk

import org.apache.spark.{SparkConf, SparkContext}


/**
 *
 * spark 进行wordCount
 */
object SparkWordCount {

  def main(args: Array[String]): Unit = {

//    val conf = new SparkConf().setAppName("SparkWordCount").setMaster("local[*]")
//    val sc = new SparkContext(conf)
//    val rdd = sc.parallelize(List(1, 2, 3, 4, 5, 6, 6)).map(_ + 1).filter(_>5).collect()
//    println(rdd.reduce(_ + _))

  }

}
